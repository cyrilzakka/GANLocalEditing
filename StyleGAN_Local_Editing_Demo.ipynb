{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Localized Semantic Editing of StyleGAN outputs\n",
    "\n",
    "Introduced in the paper:<br>\n",
    "> Edo Collins, Raja Bala, Bob Price and Sabine SÃ¼sstrunk. _Editing in Style: Uncovering the Local Semantics of GANs_.  IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2020.\n",
    "\n",
    "This demo illustrates a simple and effective method for making local, semantically-aware edits to a _target_ GAN output image. This is accomplished by borrowing styles from a _source_ image, also a GAN output.\n",
    "\n",
    "The method requires neither supervision from an external model, nor involves complex spatial morphing operations. Instead, it relies on the emergent disentanglement of semantic objects that is learned by StyleGAN during its training, which we detect using Spherical _k_-means.\n",
    "\n",
    "The implementation below relies on PyTorch and requires downloading additional parameter files found here: https://drive.google.com/open?id=1GYzEzOCaI8FUS6JHdt6g9UfNTmpO08Tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import stylegan                                     # StyleGAN model\n",
    "from stylegan_output import GANOutputs              # Data structure to hold GAN outputs\n",
    "import ptutils                                      # Helper tensor functions\n",
    "import visutils                                     # Visualization functions\n",
    "# from factor_catalog import FactorCatalog            # Spherical k-means and the M matrix (Eq. 1)\n",
    "from style2_interpolator import StyleInterpolator    # The 'sequential' style-interpolator (Eq. 5)\n",
    "import cielab                                       # Helper functions for CIELAB color-space\n",
    "torch.cuda.set_device(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'FFHQ'\n",
    "#dataset_name = 'bedrooms'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the appropriate StyleGAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/t-yazen/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "catalog = torch.load('catalogs/stylegan1_FFHQ.pkl'.format(dataset_name)) # See comment above regarding additional files\n",
    "si_wf = StyleInterpolator(catalog, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor(0.0018) tensor(0.6879) tensor(52.2493)\n",
      "tensor(0.0071) tensor(0.7265) tensor(68.7965)\n",
      "tensor(0.0021) tensor(0.3560) tensor(19.9632)\n",
      "tensor(0.0064) tensor(0.8137) tensor(75.3605)\n",
      "tensor(0.0038) tensor(0.4327) tensor(26.2488)\n",
      "tensor(0.0048) tensor(0.5194) tensor(32.5841)\n",
      "tensor(0.0048) tensor(0.5246) tensor(47.5136)\n",
      "tensor(0.0056) tensor(0.5826) tensor(60.4719)\n"
     ]
    }
   ],
   "source": [
    "select = catalog.M[6]\n",
    "print(type(select))\n",
    "# for i in range(len(catalog.M)):\n",
    "#     print(catalog.M[i].size())\n",
    "for i in range(8):\n",
    "    select = catalog.M[6][i]\n",
    "    print(torch.min(select), torch.max(select), torch.sum(select))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5a57788bb217>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtruncation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstylegan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStyleGAN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_from_pth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../karass_ckpt/ffhqE.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mg_synthesis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_noise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fixed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GANLocalEditing/stylegan.py\u001b[0m in \u001b[0;36mload_from_pth\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0msd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         max_res = max(\n\u001b[0;32m--> 493\u001b[0;31m             [int(re.search('(\\d+)x\\d+', k).group(1)) for k in sd.keys() if k.endswith('conv1.weight')])\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStyleGAN\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mG_mapping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTruncation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG_synthesis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolution\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "root_dir = 'state_dicts' # See comment above regarding additional files\n",
    "if dataset_name == 'bedrooms':\n",
    "    base_filename = 'bedrooms-256x256'\n",
    "    truncation = 0.5\n",
    "elif dataset_name == 'FFHQ':\n",
    "    base_filename = 'ffhq'\n",
    "    truncation = 0.7\n",
    "\n",
    "G = stylegan.StyleGAN.load_from_pth('../karass_ckpt/ffhqE.pt').eval()\n",
    "G = G.cuda()\n",
    "G.g_synthesis.set_noise(mode='fixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the pre-computed spherical k-means clusters, and provide them to the style interpolator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == 'FFHQ':\n",
    "    gs = GANOutputs.from_seed(5, 2001)\n",
    "elif dataset_name == 'bedrooms':\n",
    "    gs = GANOutputs.from_seed((0,33,3,19,34), 6813)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print('z: ', gs.z.size())\n",
    "    tmp_w = G.z_to_w(gs.z.cuda(), truncation=truncation)\n",
    "    print('w: ', tmp_w[0].size(), len(tmp_w))\n",
    "    gs.ys = G.w_to_ys(tmp_w)\n",
    "    print('ys: ', gs.ys[0].size(), len(gs.ys))\n",
    "    rgb = G.ys_to_rgb(gs.ys)\n",
    "    rgb = (rgb.clamp(-1, 1) + 1) / 2\n",
    "    rgb = rgb.cpu()\n",
    "    gs.rgb = ptutils.MultiResolutionStore(rgb)\n",
    "        \n",
    "    gs1 = gs[:1]\n",
    "    gs2 = gs[1:]\n",
    "\n",
    "res=256\n",
    "i, n = 0,4\n",
    "print(gs1.rgb.get(res)[i:i+n].size())\n",
    "visutils.show(gs1.rgb.get(res)[i:i+n].permute(0,2,3,1).cpu(), title='Target')\n",
    "visutils.show(gs2.rgb.get(res)[i:i+n].permute(0,2,3,1).cpu(), title='References')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer object styles from refernces to target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('gs1.ys: ', gs1.ys[0].size())\n",
    "print('gs2.ys: ', gs2.ys[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_gs = {}\n",
    "print(len(G.AdaIN_layers))\n",
    "def get_epsilons(epsilon, low_res_epsilon=0):\n",
    "    epsilons = [epsilon]*len(G.AdaIN_layers)\n",
    "    for i in range(4): epsilons[i] = low_res_epsilon\n",
    "    return epsilons\n",
    "\n",
    "if dataset_name == 'FFHQ':\n",
    "    parts_thresholds = {\n",
    "        'eyes': (0.1, get_epsilons(50, 5)),\n",
    "        'nose': (0.1, get_epsilons(30, 5)),\n",
    "        'mouth': (0.1, get_epsilons(50, 5)),\n",
    "    }\n",
    "\n",
    "elif dataset_name == 'bedrooms':\n",
    "    parts_thresholds = {\n",
    "        'bed': (0.01, get_epsilons(120)),\n",
    "        'pillow': (0.05, get_epsilons(100)),\n",
    "        'window': (0.05, get_epsilons(100)),\n",
    "    }\n",
    "\n",
    "for label, (rho, epsilon) in parts_thresholds.items():\n",
    "        key = (label)\n",
    "        part_gs[key]  = GANOutputs()\n",
    "        print(len(gs1.ys), gs1.ys[0].size(), len(gs2.ys), gs2.ys[0].size())\n",
    "        part_gs[key].ys = si_wf.interpolate_ys(gs1.ys, gs2.ys, label, rho, epsilon)\n",
    "        with torch.no_grad():\n",
    "                rgb = G.ys_to_rgb(part_gs[key].ys)\n",
    "                rgb = (rgb.clamp(-1, 1) + 1) / 2\n",
    "                rgb = rgb.cpu()\n",
    "                part_gs[key].rgb = ptutils.MultiResolutionStore(rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 256\n",
    "visutils.part_grid(gs1.rgb.get(res), gs2.rgb.get(res), {k: v.rgb.get(res) for k,v in part_gs.items()});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the MSE in CIELAB color-space, between the edited output and the target image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = 256\n",
    "normalize = lambda x: x/x.max()\n",
    "visutils.part_grid(gs1.rgb.get(res), gs2.rgb.get(res),\n",
    "                 {k: normalize(cielab.squared_error(v.rgb.get(res), gs1.rgb.get(res))) for k,v in part_gs.items()});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
